{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1a9582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| text                                                                                                                                                                                                                                                            | date                | label   | id                  | label_name      |\n",
      "|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------|:--------|:--------------------|:----------------|\n",
      "| The {@Clinton LumberKings@} beat the {@Cedar Rapids Kernels@} 4-0 in Game 1 of the Western Division finals. Evan Edwards hit a 2-run HR. WP Josh Roberson: 5 IP, 3 H, 0 R, 0 BB, 10 K #MWLplayoffs #MWLscoreboard                                               | 2019-09-08 00:00:00 | 4       | 1170516324419866624 | sports_&_gaming |\n",
      "| I would rather hear Eli Gold announce this Auburn game than these dumbasses. {@ESPN@}                                                                                                                                                                           | 2019-09-08 00:00:00 | 4       | 1170516440690176006 | sports_&_gaming |\n",
      "| Someone take my phone away, I’m trying to not look at {@Chicago Blackhawks@} home game tickets in October                                                                                                                                                       | 2019-09-08 00:00:00 | 4       | 1170516543387709440 | sports_&_gaming |\n",
      "| A year ago, Louisville struggled to beat an FCS opponent, ISU.  Yes they won 31-7, but score wasn’t indicative of the game flow.  Today, they are demoralizing a better FCS opponent in EKU. {@Coach Satterfield@} thank you!! {{USERNAME}} , glad you’re gone. | 2019-09-08 00:00:00 | 4       | 1170516620466429953 | sports_&_gaming |\n",
      "| Anyone know why the #Dodgers #Orioles game next Thursday 9/12 is on Fox?? That’s arguably the last game on the entire schedule I’d imagine being on Fox. {@Bill Shaikin@} {@Eric Stephen@} {@David Vassegh@}                                                    | 2019-09-08 00:00:00 | 4       | 1170516711411310592 | sports_&_gaming |\n",
      "\n",
      "Shape of the DataFrame: (6443, 5)\n",
      "\n",
      "Column Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6443 entries, 0 to 6442\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   text        6443 non-null   object        \n",
      " 1   date        6443 non-null   datetime64[ns]\n",
      " 2   label       6443 non-null   int64         \n",
      " 3   id          6443 non-null   int64         \n",
      " 4   label_name  6443 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(2)\n",
      "memory usage: 251.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the JSON file using the provided path\n",
    "file_path = r\"C:\\Users\\HP\\Documents\\MACHINE LEARNING CLASSIFICATION OF TWEETS-BI95CZ\\data\\CETM47_24_5-AS2-Data.json\"\n",
    "df = pd.read_json(file_path)\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# Print the shape of the DataFrame\n",
    "print(f\"\\nShape of the DataFrame: {df.shape}\")\n",
    "\n",
    "# Print the column names and their data types\n",
    "print(\"\\nColumn Information:\")\n",
    "print(df.info()) nhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4380feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels (numeric): 6\n",
      "Number of unique labels (names): 6\n",
      "\n",
      "Distribution of numeric labels:\n",
      "| label   | count   |\n",
      "|:--------|:--------|\n",
      "| 0       | 144     |\n",
      "| 1       | 287     |\n",
      "| 2       | 2512    |\n",
      "| 3       | 883     |\n",
      "| 4       | 2291    |\n",
      "| 5       | 326     |\n",
      "\n",
      "Distribution of label names:\n",
      "| label_name               | count   |\n",
      "|:-------------------------|:--------|\n",
      "| pop_culture              | 2512    |\n",
      "| sports_&_gaming          | 2291    |\n",
      "| daily_life               | 883     |\n",
      "| science_&_technology     | 326     |\n",
      "| business_&_entrepreneurs | 287     |\n",
      "| arts_&_culture           | 144     |\n"
     ]
    }
   ],
   "source": [
    "# Display number of unique labels\n",
    "num_unique_labels = df['label'].nunique()\n",
    "print(f\"Number of unique labels (numeric): {num_unique_labels}\")\n",
    "\n",
    "num_unique_label_names = df['label_name'].nunique()\n",
    "print(f\"Number of unique labels (names): {num_unique_label_names}\")\n",
    "\n",
    "# Display distribution of labels (numeric)\n",
    "print(\"\\nDistribution of numeric labels:\")\n",
    "print(df['label'].value_counts().sort_index().to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# Distribution of label names\n",
    "print(\"\\nDistribution of label names:\")\n",
    "print(df['label_name'].value_counts().to_markdown(numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a415680d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tweet Length Statistics:\n",
      "| label   | count   | mean    | std     | min   | 25%    | 50%   | 75%    | max   |\n",
      "|:--------|:--------|:--------|:--------|:------|:-------|:------|:-------|:------|\n",
      "| 0       | 144     | 180.188 | 68.0527 | 50    | 114.75 | 186   | 237.5  | 306   |\n",
      "| 1       | 287     | 195.857 | 65.6587 | 64    | 142.5  | 203   | 253    | 353   |\n",
      "| 2       | 2512    | 153.445 | 66.7246 | 39    | 98     | 138   | 207    | 325   |\n",
      "| 3       | 883     | 178.166 | 69.1297 | 38    | 117    | 177   | 240    | 338   |\n",
      "| 4       | 2291    | 167.784 | 66.6214 | 42    | 111.5  | 157   | 224    | 322   |\n",
      "| 5       | 326     | 184.755 | 69.895  | 58    | 119.25 | 183   | 249.75 | 347   |\n",
      "\n",
      "--- Examples for category: sports_&_gaming ---\n",
      "1. Everybody feeling sorry for the loaded Nets  I know a guy played every minute of a game with a 50 piece averaged a triple double and lost and yaw slandered the man ! Hold {@Kevin Durant@} to the same standard\n",
      "2. Shout out to {@Dominick Cruz@} great fight ... The champ is ready to re-clams his belt\n",
      "3. “If your not going to put up a guardrail to protect the drivers, don’t doubt their stories about what they see in there.” Hilarious {@Dale Earnhardt Jr@} #LostSpeedways\n",
      "4. The {@Development Academy@} should consider allowing one overage player per team per game. Just an idea I had coaching my first {@Development Academy@} games today with {{USERNAME}}\n",
      "5. The respect i have for {@Maurice Hooker@} skyrocketed tonight. A true warrior who laid it all on the line. ⚔️⚔️⚔️ #OrtizHooker\n",
      "\n",
      "--- Examples for category: pop_culture ---\n",
      "1. . {@Olivia Rodrigo@}  s  drivers license  scores the biggest UK sales week for a #1 debut single since {@zayn@}  s  PILLOWTALK  in 2016.\n",
      "2. I can t wait for {@COIN@} to drop the best album of the decade.\n",
      "3. ‘Breaking Bad’ Film: Go Behind-the-Scenes of ‘El Camino’ With Aaron Paul {{URL}} via {@Men s Journal@}\n",
      "4. RODGERS I JUST SAW YOU DO A MINI DISCOUNT DOUBLE CHECK!!! {@Aaron Rodgers@} {@Green Bay Packers@} {@Pat McAfee@} I wanna see him give a full all out discount double check!!!! {@State Farm@}\n",
      "5. Hi {@Most Requested Live@} ! #BTS is conquering the world right now! Please help us  celebrate by playing #MakeItRight by BTS feat. {@Lauv@} tonight on  #MostRequestedLive! {@BTS_twt@}\n",
      "\n",
      "--- Examples for category: daily_life ---\n",
      "1. JOOHEON S SMILE LIT UP THE FIRE OF HOPE IN ME EVEN MORE. GOOD THINGS WILL COME. GREAT THINGS WILL COME.  #몬베베_원호_응원해  #몬베베는_몬엑을_믿어요 {@MONSTA X@}\n",
      "2. Work hard, have fun, make history {{USERNAME}} WE LOVE YOU SOHEL  #HBDIsmartSohel #HBDSyedSohelRyan\n",
      "3. Looks like everyone on Twitter be waking up. Sorry Mr {{USERNAME}} if my drunk rambles don t make sense. Been live tweeting Pokemon for the last 6 hours  ‍♂️\n",
      "4. Delighted to have completed this course before the Christmas break on {{USERNAME}} . Really enjoyed starting my journey for Cypress automation and cannot wait to do more learning over the festive period.  a big thanks to {{USERNAME}} for kick starting me on this journey!\n",
      "5. So People on this plane are NOT MANDATED to take a #Vaccine?  Where are their #VaccinePassports?  Hell..where are their #Masks?  But you let {@Joe Biden@} strip #American citizens of their #CivilLiberties.  Make it make sense. So tired of  woke  sheep. {{URL}}\n",
      "\n",
      "--- Examples for category: business_&_entrepreneurs ---\n",
      "1. The world s second-largest truckmaker behind {{USERNAME}} said orders for its trucks, including brands such as Mack and Renault, fell 45% from the same quarter last year. {{URL}} \n",
      "2. Sparking Outrage: #lilnasX Limited Edition Nike  Satan Shoes  Will Have 666 Pairs & Contain 1 Drop Of Human Blood! - {{URL}} via {@WORLDSTARHIPHOP@} #WSHH #WORLDSTAR\n",
      "3. The Future of Bitcoin: 12 Scenarios From Bullish to Bearish {{URL}} via {@CoinDesk@}\n",
      "4.  Smoked brisket, sliced up and ready for Labor Day weekend! I used my {{USERNAME}} All-Purpose Rub to get that perfect smoke ring and bark. . ‍ Weekly Meal Delivery — Say no to meal prep every week! No more… {{URL}} \n",
      "5. *Sold out* thanks to all you generous Geordies (and adopted), so today we will send £3,000 to North East Homeless who provide a fantastic service to folk in need all year round but which is especially needed at this time of year {{USERNAME}} #NUFC ️️ {{URL}} \n",
      "\n",
      "--- Examples for category: science_&_technology ---\n",
      "1. Morning Coffee – Espresso about Security [⛔] Lock Your Mobile Devices (May 12, 2020) #protect {{USERNAME}} The number one step for protecting your mobile device is making sure it has a strong passcode or password lock on it so only you can access it.  To… {{URL}} \n",
      "2. Random Access Memory (RAM)   You can join our family  {{USERNAME}} 1️⃣ Share with your friends. 2️⃣Join our #LearnEEE family  {{USERNAME}} 3️⃣Visit our Website {{URL}} 4️⃣Visit our Youtube channel… {{URL}}\n",
      "3. A glimpse of what QCRI, R&D institutes and universities around the world are doing in digital innovation and medical research in the fight against #COVID19 {{URL}} {@HBKU@} {@Qatar Foundation@} \n",
      "4. I wonder what it s like for {@Scott Morrison@} {{USERNAME}} and their ilk knowing that their footnote to history will be  they were part of the last generation that thought they could get away with denialist conservatism by pretending climate change didn t exist ? #auspol\n",
      "5. the internet said so podcast is helping me get thru my weekend. {@Varun Thakur@} {@Aadar Malik@} {@Kautuk Srivastava@} {@Neville Shah@}\n",
      "\n",
      "--- Examples for category: arts_&_culture ---\n",
      "1. I don’t have any real New Years resolutions but if I did it would be to read and workout more often. Luckily, {@Barack Obama@} ’s new book is giving me a bit of both (get it....cuz it’s a book that’s also heavy af?). Seriously tho, I could read it for hours if I were in better shape.\n",
      "2. BLUE Falling  Stars 18(into the BLUE ... by {{USERNAME}} via {@Artfinder@} #oil #painting #art {{URL}}\n",
      "3. tgck for {{USERNAME}} !  The difference in beliefs makes all the distinction in life and death, sometimes, and Ochako cannot be bothered to understand that now as Himiko coughs and tells her to leave, a sad, love-etched smile on her face, because Ochako doesn t want to leave.\n",
      "4. Crystal Angel Vintage Taper Candle Holders by RetroMollyTreasures {{URL}} via {@Etsy@} Stop by {{URL}} for our Labor Day weekend sale 20% off of the entire store!!\n",
      "5. Truly a modern treasure trove, The Artisan Studio in Salisbury is the perfect place to browse for unusual presents. We love it! {{USERNAME}} {{URL}} \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate tweet lengths\n",
    "df['text_length'] = df['text'].apply(len)  # Character count\n",
    "\n",
    "\n",
    "# Group by label and get statistics\n",
    "length_stats = df.groupby('label')['text_length'].describe()\n",
    "print(\"\\nTweet Length Statistics:\")\n",
    "print(length_stats.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# Display example tweets\n",
    "def print_example_tweets(df, label_name, num_examples=5):\n",
    "    print(f\"\\n--- Examples for category: {label_name} ---\")\n",
    "    examples = df[df['label_name'] == label_name]['text'].sample(num_examples, random_state=42)  # Consistent examples\n",
    "    for i, example in enumerate(examples):\n",
    "        print(f\"{i+1}. {example}\")\n",
    "\n",
    "# Print examples for each category\n",
    "for label in df['label_name'].unique():\n",
    "    print_example_tweets(df, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "85bf058b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Example 1 ---\n",
      "Original: The {@Clinton LumberKings@} beat the {@Cedar Rapids Kernels@} 4-0 in Game 1 of the Western Division finals. Evan Edwards hit a 2-run HR. WP Josh Roberson: 5 IP, 3 H, 0 R, 0 BB, 10 K #MWLplayoffs #MWLscoreboard\n",
      "Cleaned:  the  lumberkings beat the  rapids kernels  in game  of the western division finals evan edwards hit a run hr wp josh roberson  ip  h  r  bb  k  \n",
      "\n",
      "\n",
      "--- Example 2 ---\n",
      "Original: I would rather hear Eli Gold announce this Auburn game than these dumbasses. {@ESPN@}\n",
      "Cleaned:  i would rather hear eli gold announce this auburn game than these dumbasses \n",
      "\n",
      "\n",
      "--- Example 3 ---\n",
      "Original: Someone take my phone away, I’m trying to not look at {@Chicago Blackhawks@} home game tickets in October \n",
      "Cleaned:  someone take my phone away im trying to not look at  blackhawks home game tickets in october \n",
      "\n",
      "\n",
      "--- Example 4 ---\n",
      "Original: A year ago, Louisville struggled to beat an FCS opponent, ISU.  Yes they won 31-7, but score wasn’t indicative of the game flow.  Today, they are demoralizing a better FCS opponent in EKU. {@Coach Satterfield@} thank you!! {{USERNAME}} , glad you’re gone.\n",
      "Cleaned:  a year ago louisville struggled to beat an fcs opponent isu  yes they won  but score wasnt indicative of the game flow  today they are demoralizing a better fcs opponent in eku  satterfield thank you username  glad youre gone\n",
      "\n",
      "\n",
      "--- Example 5 ---\n",
      "Original: Anyone know why the #Dodgers #Orioles game next Thursday 9/12 is on Fox?? That’s arguably the last game on the entire schedule I’d imagine being on Fox. {@Bill Shaikin@} {@Eric Stephen@} {@David Vassegh@}\n",
      "Cleaned:  anyone know why the   game next thursday  is on fox thats arguably the last game on the entire schedule id imagine being on fox  shaikin  stephen  vassegh\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|{{URL}}', '', text)\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    # Remove special characters and digits (keep only letters and spaces)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the 'text' column\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Display the original and cleaned text for a few examples\n",
    "for i in range(5):\n",
    "    print(f\"--- Example {i+1} ---\")\n",
    "    print(f\"Original: {df['text'][i]}\")\n",
    "    print(f\"Cleaned:  {df['cleaned_text'][i]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcb3b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Example 1 ---\n",
      "Original: The {@Clinton LumberKings@} beat the {@Cedar Rapids Kernels@} 4-0 in Game 1 of the Western Division finals. Evan Edwards hit a 2-run HR. WP Josh Roberson: 5 IP, 3 H, 0 R, 0 BB, 10 K #MWLplayoffs #MWLscoreboard\n",
      "Cleaned:  the lumberkings beat the rapids kernels in game of the western division finals evan edwards hit a run hr wp josh roberson ip h r bb k\n",
      "\n",
      "\n",
      "--- Example 2 ---\n",
      "Original: I would rather hear Eli Gold announce this Auburn game than these dumbasses. {@ESPN@}\n",
      "Cleaned:  i would rather hear eli gold announce this auburn game than these dumbasses\n",
      "\n",
      "\n",
      "--- Example 3 ---\n",
      "Original: Someone take my phone away, I’m trying to not look at {@Chicago Blackhawks@} home game tickets in October \n",
      "Cleaned:  someone take my phone away im trying to not look at blackhawks home game tickets in october\n",
      "\n",
      "\n",
      "--- Example 4 ---\n",
      "Original: A year ago, Louisville struggled to beat an FCS opponent, ISU.  Yes they won 31-7, but score wasn’t indicative of the game flow.  Today, they are demoralizing a better FCS opponent in EKU. {@Coach Satterfield@} thank you!! {{USERNAME}} , glad you’re gone.\n",
      "Cleaned:  a year ago louisville struggled to beat an fcs opponent isu yes they won but score wasnt indicative of the game flow today they are demoralizing a better fcs opponent in eku satterfield thank you username glad youre gone\n",
      "\n",
      "\n",
      "--- Example 5 ---\n",
      "Original: Anyone know why the #Dodgers #Orioles game next Thursday 9/12 is on Fox?? That’s arguably the last game on the entire schedule I’d imagine being on Fox. {@Bill Shaikin@} {@Eric Stephen@} {@David Vassegh@}\n",
      "Cleaned:  anyone know why the game next thursday is on fox thats arguably the last game on the entire schedule id imagine being on fox shaikin stephen vassegh\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|{{URL}}', '', text)\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    # Remove special characters and digits but keep only letters and spaces)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the 'text' column\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Display the original and cleaned text for a few examples\n",
    "for i in range(5):\n",
    "    print(f\"--- Example {i+1} ---\")\n",
    "    print(f\"Original: {df['text'][i]}\")\n",
    "    print(f\"Cleaned:  {df['cleaned_text'][i]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bbac14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Example 1 ---\n",
      "Original:   The {@Clinton LumberKings@} beat the {@Cedar Rapids Kernels@} 4-0 in Game 1 of the Western Division finals. Evan Edwards hit a 2-run HR. WP Josh Roberson: 5 IP, 3 H, 0 R, 0 BB, 10 K #MWLplayoffs #MWLscoreboard\n",
      "Cleaned:    the lumberkings beat the rapids kernels in game of the western division finals evan edwards hit a run hr wp josh roberson ip h r bb k\n",
      "Tokenized:  ['the', 'lumberkings', 'beat', 'the', 'rapids', 'kernels', 'in', 'game', 'of', 'the', 'western', 'division', 'finals', 'evan', 'edwards', 'hit', 'a', 'run', 'hr', 'wp', 'josh', 'roberson', 'ip', 'h', 'r', 'bb', 'k']\n",
      "\n",
      "\n",
      "--- Example 2 ---\n",
      "Original:   I would rather hear Eli Gold announce this Auburn game than these dumbasses. {@ESPN@}\n",
      "Cleaned:    i would rather hear eli gold announce this auburn game than these dumbasses\n",
      "Tokenized:  ['i', 'would', 'rather', 'hear', 'eli', 'gold', 'announce', 'this', 'auburn', 'game', 'than', 'these', 'dumbasses']\n",
      "\n",
      "\n",
      "--- Example 3 ---\n",
      "Original:   Someone take my phone away, I’m trying to not look at {@Chicago Blackhawks@} home game tickets in October \n",
      "Cleaned:    someone take my phone away im trying to not look at blackhawks home game tickets in october\n",
      "Tokenized:  ['someone', 'take', 'my', 'phone', 'away', 'im', 'trying', 'to', 'not', 'look', 'at', 'blackhawks', 'home', 'game', 'tickets', 'in', 'october']\n",
      "\n",
      "\n",
      "--- Example 4 ---\n",
      "Original:   A year ago, Louisville struggled to beat an FCS opponent, ISU.  Yes they won 31-7, but score wasn’t indicative of the game flow.  Today, they are demoralizing a better FCS opponent in EKU. {@Coach Satterfield@} thank you!! {{USERNAME}} , glad you’re gone.\n",
      "Cleaned:    a year ago louisville struggled to beat an fcs opponent isu yes they won but score wasnt indicative of the game flow today they are demoralizing a better fcs opponent in eku satterfield thank you username glad youre gone\n",
      "Tokenized:  ['a', 'year', 'ago', 'louisville', 'struggled', 'to', 'beat', 'an', 'fcs', 'opponent', 'isu', 'yes', 'they', 'won', 'but', 'score', 'wasnt', 'indicative', 'of', 'the', 'game', 'flow', 'today', 'they', 'are', 'demoralizing', 'a', 'better', 'fcs', 'opponent', 'in', 'eku', 'satterfield', 'thank', 'you', 'username', 'glad', 'youre', 'gone']\n",
      "\n",
      "\n",
      "--- Example 5 ---\n",
      "Original:   Anyone know why the #Dodgers #Orioles game next Thursday 9/12 is on Fox?? That’s arguably the last game on the entire schedule I’d imagine being on Fox. {@Bill Shaikin@} {@Eric Stephen@} {@David Vassegh@}\n",
      "Cleaned:    anyone know why the game next thursday is on fox thats arguably the last game on the entire schedule id imagine being on fox shaikin stephen vassegh\n",
      "Tokenized:  ['anyone', 'know', 'why', 'the', 'game', 'next', 'thursday', 'is', 'on', 'fox', 'thats', 'arguably', 'the', 'last', 'game', 'on', 'the', 'entire', 'schedule', 'id', 'imagine', 'being', 'on', 'fox', 'shaikin', 'stephen', 'vassegh']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "\n",
    "# Specify the download directory in my current working directory ()\n",
    "nltk_data_dir = os.path.join(os.getcwd(), 'nltk_data')\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "\n",
    "# Download the punkt tokenizer \n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt', download_dir=nltk_data_dir)\n",
    "\n",
    "# Download the punkt_tab resource \n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt_tab')\n",
    "except LookupError:\n",
    "    nltk.download('punkt_tab', download_dir=nltk_data_dir)\n",
    "\n",
    "# Tokenize the cleaned text\n",
    "df['tokenized_text'] = df['cleaned_text'].apply(word_tokenize)\n",
    "\n",
    "# Display the original, cleaned, and tokenized text for a few examples\n",
    "for i in range(5):\n",
    "    print(f\"--- Example {i+1} ---\")\n",
    "    print(f\"Original:   {df['text'][i]}\")\n",
    "    print(f\"Cleaned:    {df['cleaned_text'][i]}\")\n",
    "    print(f\"Tokenized:  {df['tokenized_text'][i]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5a61104d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (5154,)\n",
      "Shape of X_test: (1289,)\n",
      "Shape of y_train: (5154,)\n",
      "Shape of y_test: (1289,)\n",
      "\n",
      "Class distribution in y_train:\n",
      "| label   | proportion   |\n",
      "|:--------|:-------------|\n",
      "| 0       | 0.0223128    |\n",
      "| 1       | 0.0446255    |\n",
      "| 2       | 0.389794     |\n",
      "| 3       | 0.136981     |\n",
      "| 4       | 0.355646     |\n",
      "| 5       | 0.0506403    |\n",
      "\n",
      "Class distribution in y_test:\n",
      "| label   | proportion   |\n",
      "|:--------|:-------------|\n",
      "| 0       | 0.0224981    |\n",
      "| 1       | 0.0442203    |\n",
      "| 2       | 0.390225     |\n",
      "| 3       | 0.137316     |\n",
      "| 4       | 0.355314     |\n",
      "| 5       | 0.0504267    |\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df['cleaned_text']  # Using the cleaned text as features\n",
    "y = df['label']         # Using the numeric labels as the target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Print the shapes of the resulting sets\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")\n",
    "\n",
    "# Check the class distribution in the training and testing sets\n",
    "print(\"\\nClass distribution in y_train:\")\n",
    "print(y_train.value_counts(normalize=True).sort_index().to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "print(\"\\nClass distribution in y_test:\")\n",
    "print(y_test.value_counts(normalize=True).sort_index().to_markdown(numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1f6d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_tfidf: (5154, 5000)\n",
      "Shape of X_test_tfidf: (1289, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Max 5000 features preferred\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Print the shapes of the vectorized data\n",
    "print(\"Shape of X_train_tfidf:\", X_train_tfidf.shape)\n",
    "print(\"Shape of X_test_tfidf:\", X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e935fb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Multinomial Naive Bayes (BoW) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.07        29\n",
      "           1       0.63      0.33      0.44        57\n",
      "           2       0.81      0.87      0.84       503\n",
      "           3       0.61      0.69      0.65       177\n",
      "           4       0.88      0.93      0.90       458\n",
      "           5       0.75      0.42      0.53        65\n",
      "\n",
      "    accuracy                           0.80      1289\n",
      "   macro avg       0.78      0.54      0.57      1289\n",
      "weighted avg       0.80      0.80      0.78      1289\n",
      "\n",
      "\n",
      "--- Logistic Regression (BoW) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.14      0.17        29\n",
      "           1       0.47      0.49      0.48        57\n",
      "           2       0.80      0.85      0.82       503\n",
      "           3       0.60      0.56      0.58       177\n",
      "           4       0.89      0.88      0.88       458\n",
      "           5       0.71      0.69      0.70        65\n",
      "\n",
      "    accuracy                           0.78      1289\n",
      "   macro avg       0.62      0.60      0.61      1289\n",
      "weighted avg       0.77      0.78      0.77      1289\n",
      "\n",
      "\n",
      "--- Support Vector Machine (BoW) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.10      0.14        29\n",
      "           1       0.50      0.25      0.33        57\n",
      "           2       0.78      0.76      0.77       503\n",
      "           3       0.46      0.65      0.54       177\n",
      "           4       0.78      0.80      0.79       458\n",
      "           5       0.76      0.48      0.58        65\n",
      "\n",
      "    accuracy                           0.71      1289\n",
      "   macro avg       0.58      0.51      0.53      1289\n",
      "weighted avg       0.71      0.71      0.70      1289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the CountVectorizer (BoW)\n",
    "bow_vectorizer = CountVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test_bow = bow_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train models using BoW features\n",
    "mnb_bow = MultinomialNB()\n",
    "lr_bow = LogisticRegression(solver='liblinear', class_weight='balanced', random_state=42)\n",
    "svm_bow = SVC(class_weight='balanced', random_state=42)\n",
    "\n",
    "mnb_bow.fit(X_train_bow, y_train)\n",
    "lr_bow.fit(X_train_bow, y_train)\n",
    "svm_bow.fit(X_train_bow, y_train)\n",
    "\n",
    "# Make predictions on the test set using BoW features\n",
    "mnb_pred_bow = mnb_bow.predict(X_test_bow)\n",
    "lr_pred_bow = lr_bow.predict(X_test_bow)\n",
    "svm_pred_bow = svm_bow.predict(X_test_bow)\n",
    "\n",
    "# Evaluate the models with BoW features\n",
    "print(\"--- Multinomial Naive Bayes (BoW) ---\")\n",
    "print(classification_report(y_test, mnb_pred_bow))\n",
    "\n",
    "print(\"\\n--- Logistic Regression (BoW) ---\")\n",
    "print(classification_report(y_test, lr_pred_bow))\n",
    "\n",
    "print(\"\\n--- Support Vector Machine (BoW) ---\")\n",
    "print(classification_report(y_test, svm_pred_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d9a70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best alpha: 0.1\n",
      "Best Macro F1-score: 0.6147856832148909\n",
      "\n",
      "--- Multinomial Naive Bayes (BoW) - Best Model ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.21      0.28        29\n",
      "           1       0.43      0.51      0.47        57\n",
      "           2       0.84      0.83      0.84       503\n",
      "           3       0.62      0.66      0.64       177\n",
      "           4       0.89      0.90      0.90       458\n",
      "           5       0.60      0.55      0.58        65\n",
      "\n",
      "    accuracy                           0.79      1289\n",
      "   macro avg       0.64      0.61      0.62      1289\n",
      "weighted avg       0.79      0.79      0.79      1289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# Initialize the GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    MultinomialNB(), param_grid, cv=5, scoring='f1_macro', verbose=1, n_jobs=1\n",
    ")  # Using 5-fold cross-validation\n",
    "\n",
    "# Perform the grid search on the training data\n",
    "grid_search.fit(X_train_bow, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(f\"Best Macro F1-score: {best_score}\")\n",
    "\n",
    "# Train the model with the best alpha\n",
    "best_mnb = MultinomialNB(alpha=best_alpha)\n",
    "best_mnb.fit(X_train_bow, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_best_mnb = best_mnb.predict(X_test_bow)\n",
    "\n",
    "# Evaluate the model with the best alpha\n",
    "print(\"\\n--- Multinomial Naive Bayes (BoW) - Best Model ---\")\n",
    "print(classification_report(y_test, y_pred_best_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c968c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best alpha (N-grams): 0.1\n",
      "Best Macro F1-score (N-grams): 0.5898554276411468\n",
      "\n",
      "--- Multinomial Naive Bayes (N-grams) - Best Model ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.28      0.30        29\n",
      "           1       0.45      0.53      0.48        57\n",
      "           2       0.85      0.81      0.83       503\n",
      "           3       0.61      0.62      0.61       177\n",
      "           4       0.88      0.90      0.89       458\n",
      "           5       0.59      0.65      0.62        65\n",
      "\n",
      "    accuracy                           0.78      1289\n",
      "   macro avg       0.62      0.63      0.62      1289\n",
      "weighted avg       0.78      0.78      0.78      1289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the CountVectorizer with n-grams (1, 2)\n",
    "ngram_vectorizer = CountVectorizer(max_features=5000, ngram_range=(1, 2))  # Includes unigrams(1) and bigrams(2)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_ngram = ngram_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test_ngram = ngram_vectorizer.transform(X_test)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid_ngram = {'alpha': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_ngram = GridSearchCV(\n",
    "    MultinomialNB(),\n",
    "    param_grid_ngram,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',\n",
    "    verbose=1,\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "# Perform the grid search on the training data\n",
    "grid_search_ngram.fit(X_train_ngram, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_alpha_ngram = grid_search_ngram.best_params_['alpha']\n",
    "best_score_ngram = grid_search_ngram.best_score_\n",
    "\n",
    "print(f\"Best alpha (N-grams): {best_alpha_ngram}\")\n",
    "print(f\"Best Macro F1-score (N-grams): {best_score_ngram}\")\n",
    "\n",
    "# Train the model with the best alpha\n",
    "best_mnb_ngram = MultinomialNB(alpha=best_alpha_ngram)\n",
    "best_mnb_ngram.fit(X_train_ngram, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_best_mnb_ngram = best_mnb_ngram.predict(X_test_ngram)\n",
    "\n",
    "# Evaluate the model with the best alpha\n",
    "print(\"\\n--- Multinomial Naive Bayes (N-grams) - Best Model ---\")\n",
    "print(classification_report(y_test, y_pred_best_mnb_ngram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7a14bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters (Logistic Regression): {'C': 1, 'class_weight': 'balanced', 'solver': 'liblinear'}\n",
      "Best Macro F1-score (Logistic Regression): 0.6019653923471668\n",
      "\n",
      "--- Logistic Regression (BoW) - Best Model ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.14      0.17        29\n",
      "           1       0.47      0.49      0.48        57\n",
      "           2       0.80      0.85      0.82       503\n",
      "           3       0.60      0.56      0.58       177\n",
      "           4       0.89      0.88      0.88       458\n",
      "           5       0.71      0.69      0.70        65\n",
      "\n",
      "    accuracy                           0.78      1289\n",
      "   macro avg       0.62      0.60      0.61      1289\n",
      "weighted avg       0.77      0.78      0.77      1289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# I'll use the BoW features (X_train_bow, X_test_bow)\n",
    "\n",
    "# Define the parameter grid for Logistic Regression\n",
    "param_grid_lr = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs', 'sag', 'saga'],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_lr = GridSearchCV(\n",
    "    LogisticRegression(random_state=42, max_iter=1000),  # Increased max_iter\n",
    "    param_grid_lr,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',\n",
    "    verbose=1,\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "# Perform the grid search on the training data\n",
    "grid_search_lr.fit(X_train_bow, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params_lr = grid_search_lr.best_params_\n",
    "best_score_lr = grid_search_lr.best_score_\n",
    "\n",
    "print(f\"Best parameters (Logistic Regression): {best_params_lr}\")\n",
    "print(f\"Best Macro F1-score (Logistic Regression): {best_score_lr}\")\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_lr = LogisticRegression(**best_params_lr, random_state=42, max_iter=1000)\n",
    "best_lr.fit(X_train_bow, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_best_lr = best_lr.predict(X_test_bow)\n",
    "\n",
    "# Evaluate the model with the best parameters\n",
    "print(\"\\n--- Logistic Regression (BoW) - Best Model ---\")\n",
    "print(classification_report(y_test, y_pred_best_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4dd4cc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "Best parameters (SVM): {'C': 0.1, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best Macro F1-score (SVM): 0.550469735973884\n",
      "\n",
      "--- Support Vector Machine (BoW) - Best Model ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.21      0.21        29\n",
      "           1       0.39      0.49      0.43        57\n",
      "           2       0.80      0.81      0.80       503\n",
      "           3       0.55      0.59      0.57       177\n",
      "           4       0.90      0.83      0.86       458\n",
      "           5       0.68      0.68      0.68        65\n",
      "\n",
      "    accuracy                           0.75      1289\n",
      "   macro avg       0.59      0.60      0.59      1289\n",
      "weighted avg       0.76      0.75      0.76      1289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# We'll continue using the BoW features (X_train_bow, X_test_bow)\n",
    "\n",
    "# Define the parameter grid for SVM\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_svm = GridSearchCV(\n",
    "    SVC(random_state=42),\n",
    "    param_grid_svm,\n",
    "    cv=3,  # Using 3-fold cross-validation to reduce computation time for SVM\n",
    "    scoring='f1_macro',\n",
    "    verbose=1,\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "# Perform the grid search on the training data\n",
    "grid_search_svm.fit(X_train_bow, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params_svm = grid_search_svm.best_params_\n",
    "best_score_svm = grid_search_svm.best_score_\n",
    "\n",
    "print(f\"Best parameters (SVM): {best_params_svm}\")\n",
    "print(f\"Best Macro F1-score (SVM): {best_score_svm}\")\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_svm = SVC(**best_params_svm, random_state=42)\n",
    "best_svm.fit(X_train_bow, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_best_svm = best_svm.predict(X_test_bow)\n",
    "\n",
    "# Evaluate the model with the best parameters\n",
    "print(\"\\n--- Support Vector Machine (BoW) - Best Model ---\")\n",
    "print(classification_report(y_test, y_pred_best_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a180e8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Multinomial Naive Bayes (BoW, Stop Words Removed) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.17      0.23        29\n",
      "           1       0.47      0.51      0.49        57\n",
      "           2       0.84      0.85      0.84       503\n",
      "           3       0.64      0.63      0.64       177\n",
      "           4       0.89      0.91      0.90       458\n",
      "           5       0.66      0.60      0.63        65\n",
      "\n",
      "    accuracy                           0.80      1289\n",
      "   macro avg       0.64      0.61      0.62      1289\n",
      "weighted avg       0.79      0.80      0.79      1289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the CountVectorizer with stop word removal\n",
    "stop_word_vectorizer = CountVectorizer(\n",
    "    max_features=5000, stop_words='english'\n",
    ")  # Remove stop words\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_stop = stop_word_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test_stop = stop_word_vectorizer.transform(X_test)\n",
    "\n",
    "# Train the Multinomial Naive Bayes model with the best alpha\n",
    "best_alpha = 0.1  # The previously tuned alpha\n",
    "mnb_stop = MultinomialNB(alpha=best_alpha)\n",
    "mnb_stop.fit(X_train_stop, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_stop = mnb_stop.predict(X_test_stop)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\n--- Multinomial Naive Bayes (BoW, Stop Words Removed) ---\")\n",
    "print(classification_report(y_test, y_pred_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "330a6e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Example 1 ---\n",
      "Cleaned:    the lumberkings beat the rapids kernels in game of the western division finals evan edwards hit a run hr wp josh roberson ip h r bb k\n",
      "Lemmatized: the lumberkings beat the rapid kernel in game of the western division final evan edward hit a run hr wp josh roberson ip h r bb k\n",
      "\n",
      "\n",
      "--- Example 2 ---\n",
      "Cleaned:    i would rather hear eli gold announce this auburn game than these dumbasses\n",
      "Lemmatized: i would rather hear eli gold announce this auburn game than these dumbass\n",
      "\n",
      "\n",
      "--- Example 3 ---\n",
      "Cleaned:    someone take my phone away im trying to not look at blackhawks home game tickets in october\n",
      "Lemmatized: someone take my phone away im trying to not look at blackhawks home game ticket in october\n",
      "\n",
      "\n",
      "--- Example 4 ---\n",
      "Cleaned:    a year ago louisville struggled to beat an fcs opponent isu yes they won but score wasnt indicative of the game flow today they are demoralizing a better fcs opponent in eku satterfield thank you username glad youre gone\n",
      "Lemmatized: a year ago louisville struggled to beat an fcs opponent isu yes they won but score wasnt indicative of the game flow today they are demoralizing a better fcs opponent in eku satterfield thank you username glad youre gone\n",
      "\n",
      "\n",
      "--- Example 5 ---\n",
      "Cleaned:    anyone know why the game next thursday is on fox thats arguably the last game on the entire schedule id imagine being on fox shaikin stephen vassegh\n",
      "Lemmatized: anyone know why the game next thursday is on fox thats arguably the last game on the entire schedule id imagine being on fox shaikin stephen vassegh\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Download the necessary NLTK resources (if not already downloaded)\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')  # Necessary for WordNet lemmatization\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \"\"\"Lemmatizes the text using WordNetLemmatizer.\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Apply the lemmatization function to the 'cleaned_text' column\n",
    "df['lemmatized_text'] = df['cleaned_text'].apply(lemmatize_text)\n",
    "\n",
    "# Display the original cleaned text and the lemmatized text for a few examples\n",
    "for i in range(5):\n",
    "    print(f\"--- Example {i+1} ---\")\n",
    "    print(f\"Cleaned:    {df['cleaned_text'][i]}\")\n",
    "    print(f\"Lemmatized: {df['lemmatized_text'][i]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6c09b9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Multinomial Naive Bayes (BoW, Lemmatized) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.21      0.28        29\n",
      "           1       0.43      0.51      0.47        57\n",
      "           2       0.84      0.83      0.84       503\n",
      "           3       0.62      0.66      0.64       177\n",
      "           4       0.89      0.90      0.90       458\n",
      "           5       0.60      0.55      0.58        65\n",
      "\n",
      "    accuracy                           0.79      1289\n",
      "   macro avg       0.64      0.61      0.62      1289\n",
      "weighted avg       0.79      0.79      0.79      1289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Vectorize the lemmatized text\n",
    "lemmatized_vectorizer = CountVectorizer(max_features=5000)  # You can adjust max_features\n",
    "X_train_lemmatized = lemmatized_vectorizer.fit_transform(X_train)\n",
    "X_test_lemmatized = lemmatized_vectorizer.transform(X_test)\n",
    "\n",
    "# Train the Multinomial Naive Bayes model with the best alpha\n",
    "best_alpha = 0.1  # Our previously tuned alpha\n",
    "mnb_lemmatized = MultinomialNB(alpha=best_alpha)\n",
    "mnb_lemmatized.fit(X_train_lemmatized, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lemmatized = mnb_lemmatized.predict(X_test_lemmatized)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\n--- Multinomial Naive Bayes (BoW, Lemmatized) ---\")\n",
    "print(classification_report(y_test, y_pred_lemmatized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9c313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Multinomial Naive Bayes (TF-IDF) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.07      0.13        29\n",
      "           1       0.72      0.37      0.49        57\n",
      "           2       0.74      0.89      0.81       503\n",
      "           3       0.70      0.50      0.58       177\n",
      "           4       0.85      0.92      0.88       458\n",
      "           5       0.79      0.35      0.49        65\n",
      "\n",
      "    accuracy                           0.78      1289\n",
      "   macro avg       0.80      0.52      0.56      1289\n",
      "weighted avg       0.78      0.78      0.76      1289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # max_features\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Train the Multinomial Naive Bayes model with the best alpha\n",
    "best_alpha = 0.1  # Our previously tuned alpha\n",
    "mnb_tfidf = MultinomialNB(alpha=best_alpha)\n",
    "mnb_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_tfidf = mnb_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\n--- Multinomial Naive Bayes (TF-IDF) ---\")\n",
    "print(classification_report(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ec400f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Random Forest (BoW) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.07        29\n",
      "           1       0.64      0.16      0.25        57\n",
      "           2       0.64      0.91      0.75       503\n",
      "           3       0.80      0.37      0.51       177\n",
      "           4       0.80      0.78      0.79       458\n",
      "           5       0.93      0.42      0.57        65\n",
      "\n",
      "    accuracy                           0.71      1289\n",
      "   macro avg       0.80      0.44      0.49      1289\n",
      "weighted avg       0.74      0.71      0.68      1289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the CountVectorizer (the best feature extraction method gotten from previous steps)\n",
    "bow_vectorizer = CountVectorizer(max_features=5000)  # sticking to 5000 features\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=200,  # Number of trees in the forest used\n",
    "    random_state=42,  # For reproducibility\n",
    "    class_weight='balanced' # Handle class imbalance\n",
    ")\n",
    "\n",
    "# Train the Random Forest Classifier\n",
    "rf_classifier.fit(X_train_bow, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = rf_classifier.predict(X_test_bow)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\n--- Random Forest (BoW) ---\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d07cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # Important to re-import\n",
    "from sklearn.naive_bayes import MultinomialNB  # Important to re-import\n",
    "\n",
    "# Re-initialize and train the model (to ensure use of correct one)\n",
    "bow_vectorizer = CountVectorizer(max_features=5000)\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)\n",
    "\n",
    "best_alpha = 0.1\n",
    "mnb_best = MultinomialNB(alpha=best_alpha)\n",
    "mnb_best.fit(X_train_bow, y_train)\n",
    "y_pred_best = mnb_best.predict(X_test_bow)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=mnb_best.classes_,\n",
    "            yticklabels=mnb_best.classes_)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix (Multinomial Naive Bayes, BoW)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5c11d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Random Forest (BoW, Weighted Classes) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.10      0.19        29\n",
      "           1       0.70      0.12      0.21        57\n",
      "           2       0.64      0.92      0.75       503\n",
      "           3       0.83      0.41      0.55       177\n",
      "           4       0.81      0.77      0.79       458\n",
      "           5       0.87      0.40      0.55        65\n",
      "\n",
      "    accuracy                           0.72      1289\n",
      "   macro avg       0.81      0.45      0.51      1289\n",
      "weighted avg       0.75      0.72      0.69      1289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the CountVectorizer (best feature extraction method)\n",
    "bow_vectorizer = CountVectorizer(max_features=5000)\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the Random Forest Classifier with adjusted class weights\n",
    "rf_classifier_weighted = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    class_weight={0: 10, 1: 5, 2: 1, 3: 2, 4: 1, 5: 5}  # Adjusted weights\n",
    ")\n",
    "\n",
    "# Train the Random Forest Classifier\n",
    "rf_classifier_weighted.fit(X_train_bow, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf_weighted = rf_classifier_weighted.predict(X_test_bow)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\n--- Random Forest (BoW, Weighted Classes) ---\")\n",
    "print(classification_report(y_test, y_pred_rf_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ee1d0ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bi95cz_tweet_classification_vectorizer.joblib']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(mnb_best, 'bi95cz_tweet_classification_model.joblib')\n",
    "\n",
    "# Save the vectorizer\n",
    "joblib.dump(bow_vectorizer, 'bi95cz_tweet_classification_vectorizer.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
